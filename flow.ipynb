{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Preprocessing + OCR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Ramesh Kumar$ Aadhaar number is 1234-5678-9012, issued on January 15, 1990. He lives at\n",
      "123 Main Street, Bangalore, Karnataka: His mobile number is 98765-43210, and his email is\n",
      "ramesh kumar@example com_\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import easyocr\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    \n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    denoised_img = cv2.fastNlMeansDenoising(gray, None, 30, 7, 21)\n",
    "        \n",
    "    return denoised_img\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    image_path = r\"image.png\"  \n",
    "    \n",
    "\n",
    "    processed_image = preprocess_image(image_path)\n",
    "    \n",
    "    reader = easyocr.Reader(['en'])\n",
    "\n",
    "    result = reader.readtext(processed_image)\n",
    "    result_str = \"\"\n",
    "    \n",
    "    for detection in result:\n",
    "        print(detection[1])\n",
    "        result_str += detection[1] \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token  |  Predicted Label\n",
      "-------------------------\n",
      "[CLS]  |  B-CARD\n",
      "'  |  O\n",
      "ram  |  O\n",
      "##esh  |  O\n",
      "kumar  |  O\n",
      "$  |  O\n",
      "aa  |  O\n",
      "##dha  |  O\n",
      "##ar  |  O\n",
      "number  |  O\n",
      "is  |  B-CARD\n",
      "123  |  O\n",
      "##4  |  O\n",
      "-  |  O\n",
      "56  |  O\n",
      "##7  |  O\n",
      "##8  |  O\n",
      "-  |  O\n",
      "90  |  O\n",
      "##12  |  O\n",
      ",  |  B-CARD\n",
      "issued  |  O\n",
      "on  |  O\n",
      "january  |  O\n",
      "15  |  O\n",
      ",  |  B-CARD\n",
      "1990  |  O\n",
      ".  |  B-CARD\n",
      "he  |  O\n",
      "lives  |  O\n",
      "at  |  O\n",
      "##12  |  O\n",
      "##3  |  O\n",
      "main  |  O\n",
      "street  |  O\n",
      ",  |  B-CARD\n",
      "bangalore  |  O\n",
      ",  |  B-CARD\n",
      "karnataka  |  O\n",
      ":  |  O\n",
      "his  |  O\n",
      "mobile  |  O\n",
      "number  |  O\n",
      "is  |  O\n",
      "98  |  O\n",
      "##7  |  O\n",
      "##65  |  O\n",
      "-  |  O\n",
      "43  |  O\n",
      "##21  |  O\n",
      "##0  |  O\n",
      ",  |  B-CARD\n",
      "and  |  O\n",
      "his  |  O\n",
      "email  |  O\n",
      "is  |  O\n",
      "##ram  |  O\n",
      "##esh  |  O\n",
      "kumar  |  O\n",
      "@  |  O\n",
      "example  |  O\n",
      "com  |  O\n",
      "_  |  O\n",
      "[SEP]  |  B-CARD\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForTokenClassification\n",
    "import torch\n",
    "\n",
    "\n",
    "model = BertForTokenClassification.from_pretrained('./saved_model')\n",
    "tokenizer = BertTokenizer.from_pretrained('./saved_model')\n",
    "\n",
    "\n",
    "model.eval()\n",
    "\n",
    "def predict(text, model, tokenizer, label_list):\n",
    "    \n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", is_split_into_words=False, padding=True, truncation=True)\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        predictions = torch.argmax(outputs.logits, dim=2)\n",
    "\n",
    "    \n",
    "    predicted_labels = [label_list[prediction.item()] for prediction in predictions[0]]\n",
    "\n",
    "    \n",
    "    tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
    "    result = list(zip(tokens, predicted_labels))\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "label_list = ['O', 'B-NAME', 'I-NAME', 'B-AADHAAR', 'I-AADHAAR', 'B-DL', 'I-DL', \n",
    "              'B-PASSPORT', 'I-PASSPORT', 'B-DATE', 'I-DATE', 'B-ADDRESS', 'I-ADDRESS', \n",
    "              'B-MOBILE', 'I-MOBILE', 'B-EMAIL', 'I-EMAIL', 'B-BANK', 'I-BANK', \n",
    "              'B-CC', 'I-CC', 'B-MEDICAL', 'I-MEDICAL', 'B-LOAN', 'I-LOAN', \n",
    "              'B-PIN', 'I-PIN', 'B-OTP', 'I-OTP', 'B-FINANCIAL', 'I-FINANCIAL', \n",
    "              'B-IP', 'I-IP', 'B-LOGIN', 'I-LOGIN', 'B-COOKIES', 'I-COOKIES', \n",
    "              'B-CREDIT', 'I-CREDIT', 'B-INSURANCE', 'I-INSURANCE', 'B-GENETIC', \n",
    "              'I-GENETIC', 'B-BIOMETRIC', 'I-BIOMETRIC', 'B-CARD', 'I-CARD']\n",
    "\n",
    "\n",
    "predictions = predict(result_str, model, tokenizer, label_list)\n",
    "\n",
    "\n",
    "print(\"Token  |  Predicted Label\")\n",
    "print(\"-------------------------\")\n",
    "for token, label in predictions:\n",
    "    print(f\"{token}  |  {label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(predictions, columns=['Token', 'Predicted Label'])\n",
    "df.to_csv(\"ouput.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obfestication\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCR Results: [([[12, 0], [848, 0], [848, 28], [12, 28]], \"'Ramesh Kumar$ Aadhaar number is 1234-5678-9012, issued on January 15, 1990. He lives at\", 0.6290654541461264), ([[2, 30], [830, 30], [830, 58], [2, 58]], '123 Main Street, Bangalore, Karnataka: His mobile number is 98765-43210, and his email is', 0.5916109796921261), ([[4, 62], [270, 62], [270, 86], [4, 86]], 'ramesh kumar@example com_', 0.9276296836902777)]\n",
      "Match found: 'ramesh kumar@example com_' with token 'ramesh.kumar@example.com' (label: B-EMAIL)\n",
      "Obfuscation completed and saved as 'obfuscated_image.png'.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import easyocr\n",
    "from fuzzywuzzy import fuzz\n",
    "import dpctl\n",
    "from numba import cuda, jit\n",
    "from numba import float32\n",
    "\n",
    "# DPC++ function to obfuscate sensitive areas in the image\n",
    "@cuda.jit\n",
    "def obfuscate_kernel(image, boxes, labels, obfuscate_labels, output_image):\n",
    "    # Calculate thread indices\n",
    "    i = cuda.grid(1)\n",
    "    if i < boxes.shape[0]:\n",
    "        # Get box coordinates and label\n",
    "        box = boxes[i]\n",
    "        label = labels[i]\n",
    "        \n",
    "        if label in obfuscate_labels:\n",
    "            # Draw black rectangle on the output image\n",
    "            for x in range(box[0], box[2]):\n",
    "                for y in range(box[1], box[3]):\n",
    "                    output_image[y, x] = 0  # Fill with black\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    denoised_img = cv2.fastNlMeansDenoising(gray, None, 30, 7, 21)\n",
    "    return img, denoised_img\n",
    "\n",
    "def obfuscate_image(original_image, result, label_mapping, obfuscate_labels):\n",
    "    # Prepare data for GPU\n",
    "    boxes = []\n",
    "    labels = []\n",
    "    \n",
    "    for detection in result:\n",
    "        text = detection[1]  # Detected text by OCR\n",
    "        box = detection[0]  # Bounding box coordinates\n",
    "\n",
    "        # Check if the detected text corresponds to any of the obfuscate labels\n",
    "        for token, label in label_mapping.items():\n",
    "            if fuzz.ratio(text, token) >= 80:  # 80% fuzzy matching\n",
    "                boxes.append((int(box[0][0]), int(box[0][1]), int(box[2][0]), int(box[2][1])))  # (x1, y1, x2, y2)\n",
    "                labels.append(label)\n",
    "                break\n",
    "\n",
    "    boxes = np.array(boxes, dtype=np.int32)\n",
    "    labels = np.array(labels, dtype=np.object)\n",
    "\n",
    "    # Allocate output image\n",
    "    output_image = np.copy(original_image)\n",
    "\n",
    "    # Launch the kernel\n",
    "    threads_per_block = 256\n",
    "    blocks_per_grid = (boxes.shape[0] + (threads_per_block - 1)) // threads_per_block\n",
    "    obfuscate_kernel[blocks_per_grid, threads_per_block](output_image, boxes, labels, obfuscate_labels, output_image)\n",
    "\n",
    "    return output_image\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = pd.read_csv(r\"D:\\nvm\\obscure\\Code\\ouput.csv\", dtype=str)\n",
    "    label_mapping = dict(zip(df['Token'], df['Predicted Label']))  # Create a dictionary mapping\n",
    "\n",
    "    # Define a list of labels to obfuscate\n",
    "    obfuscate_labels = [label for label in label_mapping.values() if label != 'O']\n",
    "\n",
    "    image_path = r\"image.png\"\n",
    "    original_image, processed_image = preprocess_image(image_path)\n",
    "\n",
    "    reader = easyocr.Reader(['en'])\n",
    "    result = reader.readtext(processed_image)\n",
    "\n",
    "    # Print OCR results for debugging\n",
    "    print(\"OCR Results:\", result)\n",
    "\n",
    "    obfuscated_image = obfuscate_image(original_image, result, label_mapping, obfuscate_labels)\n",
    "\n",
    "    # Save the obfuscated image\n",
    "    cv2.imwrite(\"obfuscated_image.png\", obfuscated_image)\n",
    "    print(\"Obfuscation completed and saved as 'obfuscated_image.png'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
