{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Preprocessing + OCR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Ramesh Kumar$ Aadhaar number is 1234-5678-9012, issued on January 15, 1990. He lives at\n",
      "123 Main Street, Bangalore, Karnataka: His mobile number is 98765-43210, and his email is\n",
      "ramesh kumar@example com_\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import easyocr\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    \n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    denoised_img = cv2.fastNlMeansDenoising(gray, None, 30, 7, 21)\n",
    "        \n",
    "    return denoised_img\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    image_path = r\"image.png\"  \n",
    "    \n",
    "\n",
    "    processed_image = preprocess_image(image_path)\n",
    "    \n",
    "    reader = easyocr.Reader(['en'])\n",
    "\n",
    "    result = reader.readtext(processed_image)\n",
    "    result_str = \"\"\n",
    "    \n",
    "    for detection in result:\n",
    "        print(detection[1])\n",
    "        result_str += detection[1] \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCR Results: [([[14, 18], [79, 18], [79, 38], [14, 38]], 'Ramesh', 0.8249102968355082), ([[85, 19], [137, 19], [137, 37], [85, 37]], 'Kumar', 0.9999859789284535), ([[140, 12], [219, 12], [219, 42], [140, 42]], 'fadhaar', 0.51098217646642), ([[225, 17], [469, 17], [469, 37], [225, 37]], 'number is 1234-5678-9012', 0.7164455642947598), ([[493, 17], [559, 17], [559, 37], [493, 37]], 'issued', 0.9988442035278075), ([[565, 18], [669, 18], [669, 39], [565, 39]], 'on   January', 0.6041175283571303), ([[674, 16], [760, 16], [760, 40], [674, 40]], '15, 1990', 0.6332941866807235), ([[785, 17], [869, 17], [869, 37], [785, 37]], 'He lives', 0.9946862936063581), ([[875, 21], [899, 21], [899, 37], [875, 37]], 'at', 0.46582163747708755), ([[13, 39], [49, 39], [49, 59], [13, 59]], '123', 0.9997733610188607), ([[55, 39], [167, 39], [167, 59], [55, 59]], 'Main Street', 0.8075895015040541), ([[191, 37], [290, 37], [290, 63], [191, 63]], 'Bangalore', 0.789764472715864), ([[313, 39], [409, 39], [409, 59], [313, 59]], 'Karnataka', 0.9651025920525648), ([[423, 39], [529, 39], [529, 59], [423, 59]], 'His mobile', 0.9629167093301495), ([[535, 39], [751, 39], [751, 59], [535, 59]], 'number is 98765-43210', 0.8855316216061708), ([[773, 39], [939, 39], [939, 59], [773, 59]], 'and his email is', 0.616881133469367), ([[14, 60], [220, 60], [220, 84], [14, 84]], 'ramesh kumar@example', 0.7990298817092187), ([[225, 65], [259, 65], [259, 81], [225, 81]], 'com', 0.9973675445804931)]\n",
      "Match found: 'Ramesh' with token 'Ramesh' (label: B-NAME)\n",
      "Match found: 'Kumar' with token 'Kumar ' (label: I-NAME)\n",
      "Match found: 'fadhaar' with token 'Aadhaar ' (label: O)\n",
      "Match found: 'issued' with token 'issued' (label: O)\n",
      "Match found: 'on   January' with token 'January' (label: B-DATE)\n",
      "Match found: '15, 1990' with token '1990  ' (label: I-DATE)\n",
      "Match found: 'He lives' with token 'lives ' (label: O)\n",
      "Match found: 'at' with token 'at    ' (label: O)\n",
      "Match found: '123' with token '1234  ' (label: B-AADHAAR)\n",
      "Match found: 'Main Street' with token 'Street' (label: I-ADDRESS)\n",
      "Match found: 'Bangalore' with token 'Bangalore ' (label:  I-ADDRESS)\n",
      "Match found: 'Karnataka' with token 'Karnataka ' (label:  I-ADDRESS)\n",
      "Match found: 'His mobile' with token 'mobile' (label: O)\n",
      "Match found: 'ramesh kumar@example' with token 'ramesh.kumar@example.com' (label: B-EMAIL)\n",
      "Obfuscation completed and saved as 'obfuscated_image.png'.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import easyocr\n",
    "from fuzzywuzzy import fuzz\n",
    "import re\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    denoised_img = cv2.fastNlMeansDenoising(gray, None, 30, 7, 21)\n",
    "    return img, denoised_img  \n",
    "\n",
    "def normalize_text(text):\n",
    "    \"\"\"Normalize text by removing spaces, special characters and converting to lowercase.\"\"\"\n",
    "    text = re.sub(r'\\W+', '', text)  \n",
    "    return text.lower()\n",
    "\n",
    "def obfuscate_image(image, result, label_mapping):\n",
    "    for detection in result:\n",
    "        text = detection[1]  \n",
    "        box = detection[0]  \n",
    "       \n",
    "        normalized_text = normalize_text(text)\n",
    "\n",
    "        for token, label in label_mapping.items():\n",
    "            normalized_token = normalize_text(token)  \n",
    "            if fuzz.ratio(normalized_text, normalized_token) >= 75:  # 75% fuzzy matching\n",
    "                print(f\"Match found: '{text}' with token '{token}' (label: {label})\") \n",
    "                \n",
    "                if label == 'B-EMAIL':  # TO SET CONDITON : EMAIL\n",
    "                    # Draw a rectangle over the sensitive area\n",
    "                    pts = np.array(box, dtype=np.int32)\n",
    "                    cv2.polylines(image, [pts], isClosed=True, color=(0, 0, 255), thickness=2)\n",
    "                    # Overlay a solid rectangle to obfuscate\n",
    "                    cv2.fillPoly(image, [pts], (0, 0, 0))  # Fill with black color\n",
    "                break  \n",
    "\n",
    "    return image\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "   \n",
    "    df = pd.read_csv(r\"D:\\nvm\\obscure\\Code\\ouput.csv\", dtype=str)  \n",
    "\n",
    "    label_mapping = dict(zip(df['Token'], df['Predicted Label']))  \n",
    "    image_path = r\"test1.png\"\n",
    "    original_image, processed_image = preprocess_image(image_path)\n",
    "\n",
    "    reader = easyocr.Reader(['en'])\n",
    "    result = reader.readtext(processed_image)\n",
    "\n",
    "    # Print OCR results for debugging\n",
    "    print(\"OCR Results:\", result)\n",
    "\n",
    "    obfuscated_image = obfuscate_image(original_image, result, label_mapping)\n",
    "\n",
    "    cv2.imwrite(\"obfuscated_image.png\", obfuscated_image)\n",
    "    print(\"Obfuscation completed and saved as 'obfuscated_image.png'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token  |  Predicted Label\n",
      "-------------------------\n",
      "[CLS]  |  B-CARD\n",
      "'  |  O\n",
      "ram  |  O\n",
      "##esh  |  O\n",
      "kumar  |  O\n",
      "$  |  O\n",
      "aa  |  O\n",
      "##dha  |  O\n",
      "##ar  |  O\n",
      "number  |  O\n",
      "is  |  B-CARD\n",
      "123  |  O\n",
      "##4  |  O\n",
      "-  |  O\n",
      "56  |  O\n",
      "##7  |  O\n",
      "##8  |  O\n",
      "-  |  O\n",
      "90  |  O\n",
      "##12  |  O\n",
      ",  |  B-CARD\n",
      "issued  |  O\n",
      "on  |  O\n",
      "january  |  O\n",
      "15  |  O\n",
      ",  |  B-CARD\n",
      "1990  |  O\n",
      ".  |  B-CARD\n",
      "he  |  O\n",
      "lives  |  O\n",
      "at  |  O\n",
      "##12  |  O\n",
      "##3  |  O\n",
      "main  |  O\n",
      "street  |  O\n",
      ",  |  B-CARD\n",
      "bangalore  |  O\n",
      ",  |  B-CARD\n",
      "karnataka  |  O\n",
      ":  |  O\n",
      "his  |  O\n",
      "mobile  |  O\n",
      "number  |  O\n",
      "is  |  O\n",
      "98  |  O\n",
      "##7  |  O\n",
      "##65  |  O\n",
      "-  |  O\n",
      "43  |  O\n",
      "##21  |  O\n",
      "##0  |  O\n",
      ",  |  B-CARD\n",
      "and  |  O\n",
      "his  |  O\n",
      "email  |  O\n",
      "is  |  O\n",
      "##ram  |  O\n",
      "##esh  |  O\n",
      "kumar  |  O\n",
      "@  |  O\n",
      "example  |  O\n",
      "com  |  O\n",
      "_  |  O\n",
      "[SEP]  |  B-CARD\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForTokenClassification\n",
    "import torch\n",
    "\n",
    "\n",
    "model = BertForTokenClassification.from_pretrained('./saved_model')\n",
    "tokenizer = BertTokenizer.from_pretrained('./saved_model')\n",
    "\n",
    "\n",
    "model.eval()\n",
    "\n",
    "def predict(text, model, tokenizer, label_list):\n",
    "    \n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", is_split_into_words=False, padding=True, truncation=True)\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        predictions = torch.argmax(outputs.logits, dim=2)\n",
    "\n",
    "    \n",
    "    predicted_labels = [label_list[prediction.item()] for prediction in predictions[0]]\n",
    "\n",
    "    \n",
    "    tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
    "    result = list(zip(tokens, predicted_labels))\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "label_list = ['O', 'B-NAME', 'I-NAME', 'B-AADHAAR', 'I-AADHAAR', 'B-DL', 'I-DL', \n",
    "              'B-PASSPORT', 'I-PASSPORT', 'B-DATE', 'I-DATE', 'B-ADDRESS', 'I-ADDRESS', \n",
    "              'B-MOBILE', 'I-MOBILE', 'B-EMAIL', 'I-EMAIL', 'B-BANK', 'I-BANK', \n",
    "              'B-CC', 'I-CC', 'B-MEDICAL', 'I-MEDICAL', 'B-LOAN', 'I-LOAN', \n",
    "              'B-PIN', 'I-PIN', 'B-OTP', 'I-OTP', 'B-FINANCIAL', 'I-FINANCIAL', \n",
    "              'B-IP', 'I-IP', 'B-LOGIN', 'I-LOGIN', 'B-COOKIES', 'I-COOKIES', \n",
    "              'B-CREDIT', 'I-CREDIT', 'B-INSURANCE', 'I-INSURANCE', 'B-GENETIC', \n",
    "              'I-GENETIC', 'B-BIOMETRIC', 'I-BIOMETRIC', 'B-CARD', 'I-CARD']\n",
    "\n",
    "\n",
    "predictions = predict(result_str, model, tokenizer, label_list)\n",
    "\n",
    "\n",
    "print(\"Token  |  Predicted Label\")\n",
    "print(\"-------------------------\")\n",
    "for token, label in predictions:\n",
    "    print(f\"{token}  |  {label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(predictions, columns=['Token', 'Predicted Label'])\n",
    "df.to_csv(\"ouput.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obfestication\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCR Results: [([[12, 0], [848, 0], [848, 28], [12, 28]], \"'Ramesh Kumar$ Aadhaar number is 1234-5678-9012, issued on January 15, 1990. He lives at\", 0.6290654541461264), ([[2, 30], [830, 30], [830, 58], [2, 58]], '123 Main Street, Bangalore, Karnataka: His mobile number is 98765-43210, and his email is', 0.5916109796921261), ([[4, 62], [270, 62], [270, 86], [4, 86]], 'ramesh kumar@example com_', 0.9276296836902777)]\n",
      "Match found: 'ramesh kumar@example com_' with token 'ramesh.kumar@example.com' (label: B-EMAIL)\n",
      "Obfuscation completed and saved as 'obfuscated_image.png'.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import easyocr\n",
    "from fuzzywuzzy import fuzz\n",
    "import re\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    denoised_img = cv2.fastNlMeansDenoising(gray, None, 30, 7, 21)\n",
    "    return img, denoised_img  \n",
    "\n",
    "\n",
    "def obfuscate_image(image, result, label_mapping, obfuscate_labels):\n",
    "    for detection in result:\n",
    "        text = detection[1]  # Detected text by OCR\n",
    "        box = detection[0]  # Bounding box coordinates\n",
    "\n",
    "       \n",
    "\n",
    "        # Check if the detected text corresponds to any of the obfuscate labels\n",
    "        for token, label in label_mapping.items():\n",
    "            \n",
    "            if fuzz.ratio(text, token) >= 80:  # 80% fuzzy matching\n",
    "                print(f\"Match found: '{text}' with token '{token}' (label: {label})\")  # Debugging info\n",
    "                \n",
    "                if label in obfuscate_labels:  # Obfuscate only if the label is in the obfuscate list\n",
    "                    # Draw a rectangle over the sensitive area\n",
    "                    pts = np.array(box, dtype=np.int32)\n",
    "                    cv2.polylines(image, [pts], isClosed=True, color=(0, 0, 255), thickness=2)\n",
    "                    # Overlay a solid rectangle to obfuscate\n",
    "                    cv2.fillPoly(image, [pts], (0, 0, 0))  # Fill with black color\n",
    "                break  \n",
    "\n",
    "    return image\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = pd.read_csv(r\"D:\\nvm\\obscure\\Code\\ouput.csv\", dtype=str)  \n",
    "\n",
    "    label_mapping = dict(zip(df['Token'], df['Predicted Label']))  # Create a dictionary mapping\n",
    "\n",
    "    # Define a list of labels to obfuscate\n",
    "    obfuscate_labels = [label for label in label_mapping.values() if label != 'O']\n",
    "\n",
    "    image_path = r\"image.png\"\n",
    "    original_image, processed_image = preprocess_image(image_path)\n",
    "\n",
    "    reader = easyocr.Reader(['en'])\n",
    "    result = reader.readtext(processed_image)\n",
    "\n",
    "    # Print OCR results for debugging\n",
    "    print(\"OCR Results:\", result)\n",
    "\n",
    "    obfuscated_image = obfuscate_image(original_image, result, label_mapping, obfuscate_labels)\n",
    "\n",
    "    cv2.imwrite(\"obfuscated_image.png\", obfuscated_image)\n",
    "    print(\"Obfuscation completed and saved as 'obfuscated_image.png'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
